{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","source":["# **Neural Machine Translation**\n","### Deep Learning Project\n","\n","> ## ***Model 4:***\n","> ### **Encoder** - Embedding layer + 2 LSTM layers\n","> ### **Decoder** - Embedding + LSTM + **Attention Mechanism**"],"metadata":{"id":"ZL_i_Qgk-hod"}},{"cell_type":"markdown","source":["### **Preprocessing Pipeline:**\n","1. Load & examine the data.\n","2. Cleaning the data. \n","  * Converting the data into an array for easy implementation.\n","  * Reducing the size of dataset to save the computation cost.(Only in this case)\n","  * Removing irrelevant text like attribution details\n","  * Splitting each sample/text into English-German pairs.\n","  * Removing punctuations.\n","  * Converting the text to lower case.\n","3. Tokenizing & vectorizing the text into numerical sequences.\n","4. Padding those sequences with 0’s to bring them to same length."],"metadata":{"id":"4JNgtTKytMoW"}},{"cell_type":"markdown","source":["### **Importing required libraries**"],"metadata":{"id":"pPZAb_iTr5RH"}},{"cell_type":"code","metadata":{"id":"jK88JoQ79a_G"},"source":["import tensorflow as tf\n","import tensorflow.keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Input, dot, Activation, Concatenate\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import initializers, regularizers, constraints\n","\n","from sklearn.model_selection import train_test_split\n","\n","!pip install mojimoji\n","!pip install sentencepiece\n","import mojimoji\n","import pandas as pd\n","import numpy as np\n","import re\n","import matplotlib.pyplot as plt\n","import io\n","\n","import nltk\n","import unicodedata\n","import sentencepiece as spm\n","\n","# ignore warning\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","print(tf.__version__)\n","# gpu\n","tf.test.is_gpu_available() "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D-4m5RN0zrp5","executionInfo":{"status":"ok","timestamp":1667603216961,"user_tz":-330,"elapsed":4060,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}},"outputId":"27840730-4667-4ccd-cbed-0e65c00b2d2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"WLgyXVAy9bAN"},"source":["def normalize_english(english_text, german_text):\n","    \n","    input_value = []\n","    target_value = []\n","    \n","    for en_text, deu_text in zip(english_text, german_text):\n","        \n","        # normalize English\n","\n","        en_text = \"start_ \" + en_text + \" _end\"\n","        # input value doesn't need  a START and END sentence  \n","        input_value.append(en_text)\n","\n","        # normalize Japanese\n","\n","        # add StTART and END sentence\n","        deu_text = \"start_ \" + deu_text + \" _end\"\n","        \n","        target_value.append(deu_text)\n","\n","    return input_value, target_value"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Importing the dataset**"],"metadata":{"id":"G595sAlfv46o"}},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DLProject/deu_eng1.csv\")\n","df1 = df\n","df1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"d_Zp0_HAz-Gm","executionInfo":{"status":"ok","timestamp":1667603606728,"user_tz":-330,"elapsed":454,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}},"outputId":"4417f7f4-6c61-4303-9c81-ec902263cbfa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Unnamed: 0           English                   German\n","0               0                go                      geh\n","1               1                hi                    hallo\n","2               2                hi                grüß gott\n","3               3               run                     lauf\n","4               4               run                     lauf\n","...           ...               ...                      ...\n","24995       24995  im not giving up       ich gebe nicht auf\n","24996       24996  im not going out       ich gehe nicht aus\n","24997       24997  im not going out      ich gehe nicht raus\n","24998       24998  im not in boston  ich bin nicht in boston\n","24999       24999  im not like that         so bin ich nicht\n","\n","[25000 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-3387b344-53ee-4d27-a243-84efa3259101\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>English</th>\n","      <th>German</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>go</td>\n","      <td>geh</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>hi</td>\n","      <td>hallo</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>hi</td>\n","      <td>grüß gott</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>run</td>\n","      <td>lauf</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>run</td>\n","      <td>lauf</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>24995</td>\n","      <td>im not giving up</td>\n","      <td>ich gebe nicht auf</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>24996</td>\n","      <td>im not going out</td>\n","      <td>ich gehe nicht aus</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>24997</td>\n","      <td>im not going out</td>\n","      <td>ich gehe nicht raus</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>24998</td>\n","      <td>im not in boston</td>\n","      <td>ich bin nicht in boston</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>24999</td>\n","      <td>im not like that</td>\n","      <td>so bin ich nicht</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3387b344-53ee-4d27-a243-84efa3259101')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3387b344-53ee-4d27-a243-84efa3259101 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3387b344-53ee-4d27-a243-84efa3259101');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["df1['English'] = \"start_ \" + df1['English'] + \" _end\"\n","df1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"80Vy45TJ5DUN","executionInfo":{"status":"ok","timestamp":1667603609124,"user_tz":-330,"elapsed":6,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}},"outputId":"42f9e60b-36bd-4424-b5f1-3e7fa977f9e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Unnamed: 0                       English                   German\n","0               0                start_ go _end                      geh\n","1               1                start_ hi _end                    hallo\n","2               2                start_ hi _end                grüß gott\n","3               3               start_ run _end                     lauf\n","4               4               start_ run _end                     lauf\n","...           ...                           ...                      ...\n","24995       24995  start_ im not giving up _end       ich gebe nicht auf\n","24996       24996  start_ im not going out _end       ich gehe nicht aus\n","24997       24997  start_ im not going out _end      ich gehe nicht raus\n","24998       24998  start_ im not in boston _end  ich bin nicht in boston\n","24999       24999  start_ im not like that _end         so bin ich nicht\n","\n","[25000 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-a66448e0-e1c5-490d-a1ba-505342e71d8b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>English</th>\n","      <th>German</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>start_ go _end</td>\n","      <td>geh</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>start_ hi _end</td>\n","      <td>hallo</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>start_ hi _end</td>\n","      <td>grüß gott</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>start_ run _end</td>\n","      <td>lauf</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>start_ run _end</td>\n","      <td>lauf</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>24995</td>\n","      <td>start_ im not giving up _end</td>\n","      <td>ich gebe nicht auf</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>24996</td>\n","      <td>start_ im not going out _end</td>\n","      <td>ich gehe nicht aus</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>24997</td>\n","      <td>start_ im not going out _end</td>\n","      <td>ich gehe nicht raus</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>24998</td>\n","      <td>start_ im not in boston _end</td>\n","      <td>ich bin nicht in boston</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>24999</td>\n","      <td>start_ im not like that _end</td>\n","      <td>so bin ich nicht</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a66448e0-e1c5-490d-a1ba-505342e71d8b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a66448e0-e1c5-490d-a1ba-505342e71d8b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a66448e0-e1c5-490d-a1ba-505342e71d8b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["df1['German'] = \"start_ \" + df1['German'] + \" _end\"\n","df1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"D44grxl254r5","executionInfo":{"status":"ok","timestamp":1667603613276,"user_tz":-330,"elapsed":666,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}},"outputId":"15de3eef-9430-47a5-bc98-2011e5e48f6e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Unnamed: 0                       English  \\\n","0               0                start_ go _end   \n","1               1                start_ hi _end   \n","2               2                start_ hi _end   \n","3               3               start_ run _end   \n","4               4               start_ run _end   \n","...           ...                           ...   \n","24995       24995  start_ im not giving up _end   \n","24996       24996  start_ im not going out _end   \n","24997       24997  start_ im not going out _end   \n","24998       24998  start_ im not in boston _end   \n","24999       24999  start_ im not like that _end   \n","\n","                                    German  \n","0                          start_ geh _end  \n","1                        start_ hallo _end  \n","2                    start_ grüß gott _end  \n","3                         start_ lauf _end  \n","4                         start_ lauf _end  \n","...                                    ...  \n","24995       start_ ich gebe nicht auf _end  \n","24996       start_ ich gehe nicht aus _end  \n","24997      start_ ich gehe nicht raus _end  \n","24998  start_ ich bin nicht in boston _end  \n","24999         start_ so bin ich nicht _end  \n","\n","[25000 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-b46efd33-a3e4-4217-903a-9c054cf8e3ed\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>English</th>\n","      <th>German</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>start_ go _end</td>\n","      <td>start_ geh _end</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>start_ hi _end</td>\n","      <td>start_ hallo _end</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>start_ hi _end</td>\n","      <td>start_ grüß gott _end</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>start_ run _end</td>\n","      <td>start_ lauf _end</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>start_ run _end</td>\n","      <td>start_ lauf _end</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>24995</td>\n","      <td>start_ im not giving up _end</td>\n","      <td>start_ ich gebe nicht auf _end</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>24996</td>\n","      <td>start_ im not going out _end</td>\n","      <td>start_ ich gehe nicht aus _end</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>24997</td>\n","      <td>start_ im not going out _end</td>\n","      <td>start_ ich gehe nicht raus _end</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>24998</td>\n","      <td>start_ im not in boston _end</td>\n","      <td>start_ ich bin nicht in boston _end</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>24999</td>\n","      <td>start_ im not like that _end</td>\n","      <td>start_ so bin ich nicht _end</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b46efd33-a3e4-4217-903a-9c054cf8e3ed')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b46efd33-a3e4-4217-903a-9c054cf8e3ed button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b46efd33-a3e4-4217-903a-9c054cf8e3ed');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"ZMlaIsar9bAf"},"source":["# tokenize\n","tokenize each language word based on space"]},{"cell_type":"code","metadata":{"id":"ACN_sW7u9bAh"},"source":["def tokenize(lang):\n","    # vectorize a text corpus\n","    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","        filters=' ')\n","\n","    # updates internal vocabulary based on a list of texts\n","    # e.g. \"[this place is good ]\"→{this:2, place:3, is:1, good:4} \"\n","    lang_tokenizer.fit_on_texts(lang)\n","\n","    # Transforms each text in texts to a sequence of integers.\n","    # e.g. this place is good → [[2, 3, 1, 4]]\n","    tensor = lang_tokenizer.texts_to_sequences(lang)\n","\n","    # transform a list of num sample into a 2D Numpy array of shape \n","    # Fixed length because length of sequence of integers are different\n","    # return (len(sequences), maxlen)\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n","                                                          padding='post')\n","    return tensor, lang_tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KDfQw_5t9bA5"},"source":["# create clean dataset"]},{"cell_type":"code","metadata":{"id":"sIM8-10h9bA6"},"source":["# cleate a clean dataset\n","def create_dataset(en, ja):\n","    \n","    # input_tensor, target_tensor: 2d numpy array\n","    # input_lang_tokenize, target_lang_tokenize: word dictionary\n","    input_tensor, input_lang_tokenize = tokenize(en)\n","    target_tensor, target_lang_tokenize = tokenize(ja)\n","\n","    return input_tensor, target_tensor, input_lang_tokenize, target_lang_tokenize"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEJJ9BMgATdD"},"source":["input_tensor, target_tensor, input_lang_tokenize, target_lang_tokenize = create_dataset(df1['English'], df1['German'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_lang_tokenize.word_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CB2erhOH12cw","executionInfo":{"status":"ok","timestamp":1667603618861,"user_tz":-330,"elapsed":23,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}},"outputId":"d535c829-81ce-45d2-d5d5-159df21a5eb7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'start_': 1,\n"," '_end': 2,\n"," 'ich': 3,\n"," 'tom': 4,\n"," 'ist': 5,\n"," 'sie': 6,\n"," 'es': 7,\n"," 'das': 8,\n"," 'nicht': 9,\n"," 'du': 10,\n"," 'bin': 11,\n"," 'wir': 12,\n"," 'hat': 13,\n"," 'er': 14,\n"," 'habe': 15,\n"," 'ein': 16,\n"," 'zu': 17,\n"," 'war': 18,\n"," 'mich': 19,\n"," 'mir': 20,\n"," 'sind': 21,\n"," 'die': 22,\n"," 'ihr': 23,\n"," 'auf': 24,\n"," 'kann': 25,\n"," 'dich': 26,\n"," 'hier': 27,\n"," 'uns': 28,\n"," 'haben': 29,\n"," 'bist': 30,\n"," 'eine': 31,\n"," 'sich': 32,\n"," 'an': 33,\n"," 'werde': 34,\n"," 'einen': 35,\n"," 'was': 36,\n"," 'wie': 37,\n"," 'wer': 38,\n"," 'jetzt': 39,\n"," 'aus': 40,\n"," 'gehen': 41,\n"," 'der': 42,\n"," 'gut': 43,\n"," 'sehr': 44,\n"," 'mag': 45,\n"," 'in': 46,\n"," 'mein': 47,\n"," 'wird': 48,\n"," 'ihn': 49,\n"," 'dir': 50,\n"," 'den': 51,\n"," 'so': 52,\n"," 'mit': 53,\n"," 'sein': 54,\n"," 'hast': 55,\n"," 'noch': 56,\n"," 'bitte': 57,\n"," 'meine': 58,\n"," 'euch': 59,\n"," 'da': 60,\n"," 'liebe': 61,\n"," 'wurde': 62,\n"," 'kein': 63,\n"," 'können': 64,\n"," 'lass': 65,\n"," 'nach': 66,\n"," 'geht': 67,\n"," 'will': 68,\n"," 'werden': 69,\n"," 'alle': 70,\n"," 'seid': 71,\n"," 'hause': 72,\n"," 'komm': 73,\n"," 'mal': 74,\n"," 'muss': 75,\n"," 'mach': 76,\n"," 'weiß': 77,\n"," 'für': 78,\n"," 'brauche': 79,\n"," 'hatte': 80,\n"," 'machen': 81,\n"," 'wo': 82,\n"," 'gerade': 83,\n"," 'niemand': 84,\n"," 'auto': 85,\n"," 'tun': 86,\n"," 'helfen': 87,\n"," 'gesehen': 88,\n"," 'viel': 89,\n"," 'auch': 90,\n"," 'schon': 91,\n"," 'kannst': 92,\n"," 'geh': 93,\n"," 'kommen': 94,\n"," 'einfach': 95,\n"," 'im': 96,\n"," 'keine': 97,\n"," 'hund': 98,\n"," 'gib': 99,\n"," 'warum': 100,\n"," 'gemacht': 101,\n"," 'beschäftigt': 102,\n"," 'ging': 103,\n"," 'weg': 104,\n"," 'dem': 105,\n"," 'deine': 106,\n"," 'dein': 107,\n"," 'hasse': 108,\n"," 'kommt': 109,\n"," 'essen': 110,\n"," 'sehen': 111,\n"," 'nichts': 112,\n"," 'etwas': 113,\n"," 'sieht': 114,\n"," 'macht': 115,\n"," 'sah': 116,\n"," 'sei': 117,\n"," 'nie': 118,\n"," 'habt': 119,\n"," 'weiter': 120,\n"," 'ihnen': 121,\n"," 'buch': 122,\n"," 'dass': 123,\n"," 'schnell': 124,\n"," 'um': 125,\n"," 'gefunden': 126,\n"," 'ab': 127,\n"," 'kam': 128,\n"," 'gehe': 129,\n"," 'sicher': 130,\n"," 'maria': 131,\n"," 'geld': 132,\n"," 'wieder': 133,\n"," 'waren': 134,\n"," 'dort': 135,\n"," 'darf': 136,\n"," 'glücklich': 137,\n"," 'zeit': 138,\n"," 'mehr': 139,\n"," 'heute': 140,\n"," 'krank': 141,\n"," 'ihm': 142,\n"," 'nur': 143,\n"," 'lasst': 144,\n"," 'von': 145,\n"," 'müde': 146,\n"," 'am': 147,\n"," 'immer': 148,\n"," 'lassen': 149,\n"," 'hör': 150,\n"," 'allein': 151,\n"," 'diese': 152,\n"," 'tut': 153,\n"," 'verloren': 154,\n"," 'gerne': 155,\n"," 'alles': 156,\n"," 'versuchen': 157,\n"," 'spät': 158,\n"," 'gehört': 159,\n"," 'arbeit': 160,\n"," 'fühle': 161,\n"," 'zurück': 162,\n"," 'bei': 163,\n"," 'leben': 164,\n"," 'recht': 165,\n"," 'getan': 166,\n"," 'toms': 167,\n"," 'gegangen': 168,\n"," 'müssen': 169,\n"," 'alt': 170,\n"," 'spaß': 171,\n"," 'weh': 172,\n"," 'möchte': 173,\n"," 'meinen': 174,\n"," 'doch': 175,\n"," 'bleiben': 176,\n"," 'vor': 177,\n"," 'fertig': 178,\n"," 'gesagt': 179,\n"," 'dieses': 180,\n"," 'groß': 181,\n"," 'ruhig': 182,\n"," 'nimm': 183,\n"," 'schlecht': 184,\n"," 'heiß': 185,\n"," 'komme': 186,\n"," 'fahren': 187,\n"," 'und': 188,\n"," 'liebt': 189,\n"," 'scheint': 190,\n"," 'wirklich': 191,\n"," 'kalt': 192,\n"," 'brauchen': 193,\n"," 'kenne': 194,\n"," 'wissen': 195,\n"," 'angst': 196,\n"," 'katze': 197,\n"," 'gegessen': 198,\n"," 'ganz': 199,\n"," 'ihre': 200,\n"," 'mann': 201,\n"," 'nett': 202,\n"," 'verrückt': 203,\n"," 'sterben': 204,\n"," 'keinen': 205,\n"," 'warten': 206,\n"," 'schau': 207,\n"," 'hin': 208,\n"," 'her': 209,\n"," 'schlüssel': 210,\n"," 'jemand': 211,\n"," 'tag': 212,\n"," 'zum': 213,\n"," 'ja': 214,\n"," 'wütend': 215,\n"," 'vielleicht': 216,\n"," 'hören': 217,\n"," 'ziemlich': 218,\n"," 'mache': 219,\n"," 'gewonnen': 220,\n"," 'traurig': 221,\n"," 'ordnung': 222,\n"," 'weinen': 223,\n"," 'gefällt': 224,\n"," 'fühlte': 225,\n"," 'gefallen': 226,\n"," 'dies': 227,\n"," 'los': 228,\n"," 'gern': 229,\n"," 'könnte': 230,\n"," 'tür': 231,\n"," 'sag': 232,\n"," 'tee': 233,\n"," 'gewinnen': 234,\n"," 'würde': 235,\n"," 'angerufen': 236,\n"," 'verletzt': 237,\n"," 'könnt': 238,\n"," 'jung': 239,\n"," 'braucht': 240,\n"," 'vater': 241,\n"," 'kinder': 242,\n"," 'siehst': 243,\n"," 'bier': 244,\n"," 'wirst': 245,\n"," 'bleib': 246,\n"," 'einmal': 247,\n"," 'arbeiten': 248,\n"," 'schwimmen': 249,\n"," 'halte': 250,\n"," 'sagen': 251,\n"," 'bereit': 252,\n"," 'schlafen': 253,\n"," 'fuß': 254,\n"," 'betrunken': 255,\n"," 'draußen': 256,\n"," 'gekauft': 257,\n"," 'hilfe': 258,\n"," 'warte': 259,\n"," 'ernst': 260,\n"," 'nehmen': 261,\n"," 'tot': 262,\n"," 'lesen': 263,\n"," 'rein': 264,\n"," 'frei': 265,\n"," 'reich': 266,\n"," 'sehe': 267,\n"," 'aufhören': 268,\n"," 'verärgert': 269,\n"," 'esse': 270,\n"," 'großartig': 271,\n"," 'wollen': 272,\n"," 'gibt': 273,\n"," 'augen': 274,\n"," 'glück': 275,\n"," 'hört': 276,\n"," 'neu': 277,\n"," 'schön': 278,\n"," 'okay': 279,\n"," 'wasser': 280,\n"," 'musst': 281,\n"," 'fast': 282,\n"," 'mary': 283,\n"," 'seien': 284,\n"," 'sagte': 285,\n"," 'hut': 286,\n"," 'keiner': 287,\n"," 'boston': 288,\n"," 'thomas': 289,\n"," 'wusste': 290,\n"," 'singen': 291,\n"," 'still': 292,\n"," 'bus': 293,\n"," 'lieben': 294,\n"," 'diesen': 295,\n"," 'arm': 296,\n"," 'herein': 297,\n"," 'versucht': 298,\n"," 'gekommen': 299,\n"," 'bett': 300,\n"," 'gab': 301,\n"," 'früh': 302,\n"," 'vorbei': 303,\n"," 'wein': 304,\n"," 'mögen': 305,\n"," 'selbst': 306,\n"," 'wagen': 307,\n"," 'jeder': 308,\n"," 'fragen': 309,\n"," 'raus': 310,\n"," 'laufen': 311,\n"," 'hoffe': 312,\n"," 'besser': 313,\n"," 'kaffee': 314,\n"," 'haus': 315,\n"," 'wach': 316,\n"," 'setz': 317,\n"," 'gestorben': 318,\n"," 'leid': 319,\n"," 'warst': 320,\n"," 'dumm': 321,\n"," 'glaube': 322,\n"," 'hol': 323,\n"," 'dran': 324,\n"," 'steht': 325,\n"," 'hunde': 326,\n"," 'vermisse': 327,\n"," 'stand': 328,\n"," 'vorsichtig': 329,\n"," 'eins': 330,\n"," 'zur': 331,\n"," 'schule': 332,\n"," 'nervös': 333,\n"," 'man': 334,\n"," 'schüchtern': 335,\n"," 'tu': 336,\n"," 'bekommen': 337,\n"," 'funktioniert': 338,\n"," 'vertrauen': 339,\n"," 'reden': 340,\n"," 'langsam': 341,\n"," 'junge': 342,\n"," 'hunger': 343,\n"," 'wäre': 344,\n"," 'worden': 345,\n"," 'verstehe': 346,\n"," 'getroffen': 347,\n"," 'finden': 348,\n"," 'rot': 349,\n"," 'bald': 350,\n"," 'uhr': 351,\n"," 'milch': 352,\n"," 'arbeite': 353,\n"," 'arzt': 354,\n"," 'willst': 355,\n"," 'dieser': 356,\n"," 'deinen': 357,\n"," 'süß': 358,\n"," 'ins': 359,\n"," 'gute': 360,\n"," 'weit': 361,\n"," 'geben': 362,\n"," 'schuld': 363,\n"," 'fisch': 364,\n"," 'französisch': 365,\n"," 'kennt': 366,\n"," 'eure': 367,\n"," 'schien': 368,\n"," 'hab': 369,\n"," 'nein': 370,\n"," 'behalten': 371,\n"," 'schwach': 372,\n"," 'böse': 373,\n"," 'machte': 374,\n"," 'hungrig': 375,\n"," 'witze': 376,\n"," 'fahrrad': 377,\n"," 'frag': 378,\n"," 'stehen': 379,\n"," 'blieb': 380,\n"," 'dabei': 381,\n"," 'vergessen': 382,\n"," 'stimmt': 383,\n"," 'verwirrt': 384,\n"," 'frau': 385,\n"," 'sohn': 386,\n"," 'spielen': 387,\n"," 'wohl': 388,\n"," 'davon': 389,\n"," 'hatten': 390,\n"," 'liegt': 391,\n"," 'zuerst': 392,\n"," 'geworden': 393,\n"," 'seine': 394,\n"," 'wollte': 395,\n"," 'zwei': 396,\n"," 'rufen': 397,\n"," 'ruhe': 398,\n"," 'sofort': 399,\n"," 'stark': 400,\n"," 'lügen': 401,\n"," 'lustig': 402,\n"," 'bisschen': 403,\n"," 'sage': 404,\n"," 'kennen': 405,\n"," 'tasche': 406,\n"," 'katzen': 407,\n"," 'ausruhen': 408,\n"," 'tanzen': 409,\n"," 'mutter': 410,\n"," 'hasst': 411,\n"," 'spiele': 412,\n"," 'sollte': 413,\n"," 'rannte': 414,\n"," 'zieh': 415,\n"," 'ruf': 416,\n"," 'kurz': 417,\n"," 'fangen': 418,\n"," 'geschafft': 419,\n"," 'geholfen': 420,\n"," 'rennen': 421,\n"," 'geschlagen': 422,\n"," 'langweilig': 423,\n"," 'fernseher': 424,\n"," 'wahr': 425,\n"," 'bring': 426,\n"," 'damit': 427,\n"," 'als': 428,\n"," 'sorgen': 429,\n"," 'trinken': 430,\n"," 'zimmer': 431,\n"," 'magst': 432,\n"," 'runter': 433,\n"," 'iss': 434,\n"," 'gehts': 435,\n"," 'dick': 436,\n"," 'cool': 437,\n"," 'zuhause': 438,\n"," 'fehlt': 439,\n"," 'kochen': 440,\n"," 'gebissen': 441,\n"," 'faul': 442,\n"," 'sieh': 443,\n"," 'anfangen': 444,\n"," 'einsam': 445,\n"," 'verlieren': 446,\n"," 'nähe': 447,\n"," 'witz': 448,\n"," 'gegeben': 449,\n"," 'isst': 450,\n"," 'trinke': 451,\n"," 'taxi': 452,\n"," 'schwer': 453,\n"," 'haare': 454,\n"," 'plan': 455,\n"," 'denke': 456,\n"," 'hallo': 457,\n"," 'einverstanden': 458,\n"," 'läuft': 459,\n"," 'leise': 460,\n"," 'hart': 461,\n"," 'wen': 462,\n"," 'trink': 463,\n"," 'job': 464,\n"," 'mädchen': 465,\n"," 'nehme': 466,\n"," 'rauchen': 467,\n"," 'daran': 468,\n"," 'hätte': 469,\n"," 'unser': 470,\n"," 'zeig': 471,\n"," 'leicht': 472,\n"," 'meinem': 473,\n"," 'idee': 474,\n"," 'schlechter': 475,\n"," 'tue': 476,\n"," 'bezahlt': 477,\n"," 'weinte': 478,\n"," 'fallen': 479,\n"," 'sprach': 480,\n"," 'sprich': 481,\n"," 'hierher': 482,\n"," 'blau': 483,\n"," 'bestürzt': 484,\n"," 'arbeitet': 485,\n"," 'kaputt': 486,\n"," 'stimme': 487,\n"," 'bezahlen': 488,\n"," 'neues': 489,\n"," 'oft': 490,\n"," 'sprechen': 491,\n"," 'rief': 492,\n"," 'brauchst': 493,\n"," 'euer': 494,\n"," 'ließ': 495,\n"," 'große': 496,\n"," 'konnte': 497,\n"," 'fang': 498,\n"," 'gelogen': 499,\n"," 'hilf': 500,\n"," 'perfekt': 501,\n"," 'lächelte': 502,\n"," 'abend': 503,\n"," 'seltsam': 504,\n"," 'nahm': 505,\n"," 'dunkel': 506,\n"," 'warm': 507,\n"," 'fing': 508,\n"," 'klug': 509,\n"," 'lebt': 510,\n"," 'alleine': 511,\n"," 'holen': 512,\n"," 'kind': 513,\n"," 'karte': 514,\n"," 'freude': 515,\n"," 'morgen': 516,\n"," 'haar': 517,\n"," 'gebracht': 518,\n"," 'gewarnt': 519,\n"," 'ihren': 520,\n"," 'echt': 521,\n"," 'vertraut': 522,\n"," 'versuch': 523,\n"," 'meinung': 524,\n"," 'fahre': 525,\n"," 'trinkt': 526,\n"," 'lese': 527,\n"," 'unrecht': 528,\n"," 'oben': 529,\n"," 'schwarz': 530,\n"," 'montag': 531,\n"," 'mittagessen': 532,\n"," 'einer': 533,\n"," 'vermissen': 534,\n"," 'eingeladen': 535,\n"," 'kaum': 536,\n"," 'verdient': 537,\n"," 'unsere': 538,\n"," 'genug': 539,\n"," 'klein': 540,\n"," 'großer': 541,\n"," 'wort': 542,\n"," 'lief': 543,\n"," 'geweint': 544,\n"," 'fort': 545,\n"," 'fuhr': 546,\n"," 'unhöflich': 547,\n"," 'klar': 548,\n"," 'über': 549,\n"," 'setzen': 550,\n"," 'halten': 551,\n"," 'probier': 552,\n"," 'lügt': 553,\n"," 'folgen': 554,\n"," 'entkommen': 555,\n"," 'fest': 556,\n"," 'falsch': 557,\n"," 'guter': 558,\n"," 'freundlich': 559,\n"," 'geschickt': 560,\n"," 'mensch': 561,\n"," 'höre': 562,\n"," 'liebte': 563,\n"," 'dafür': 564,\n"," 'dreißig': 565,\n"," 'passiert': 566,\n"," 'wette': 567,\n"," 'sicherheit': 568,\n"," 'kaufen': 569,\n"," 'dazu': 570,\n"," 'gefragt': 571,\n"," 'geliebt': 572,\n"," 'musik': 573,\n"," 'geküsst': 574,\n"," 'bücher': 575,\n"," 'hoffnung': 576,\n"," 'weißt': 577,\n"," 'lehrer': 578,\n"," 'pferd': 579,\n"," 'zufrieden': 580,\n"," 'platz': 581,\n"," 'apfel': 582,\n"," 'anderen': 583,\n"," 'weise': 584,\n"," 'bleibt': 585,\n"," 'nass': 586,\n"," 'legen': 587,\n"," 'öffne': 588,\n"," 'später': 589,\n"," 'reparieren': 590,\n"," 'gemein': 591,\n"," 'hilft': 592,\n"," 'stehe': 593,\n"," 'halt': 594,\n"," 'schrecklich': 595,\n"," 'seinen': 596,\n"," 'unten': 597,\n"," 'verlassen': 598,\n"," 'reis': 599,\n"," 'gleich': 600,\n"," 'drinnen': 601,\n"," 'problem': 602,\n"," 'schläft': 603,\n"," 'trank': 604,\n"," 'entlassen': 605,\n"," 'schmerzen': 606,\n"," 'darüber': 607,\n"," 'lange': 608,\n"," 'leiden': 609,\n"," 'lernen': 610,\n"," 'einem': 611,\n"," 'schuldig': 612,\n"," 'gelesen': 613,\n"," 'familie': 614,\n"," 'freunde': 615,\n"," 'wann': 616,\n"," 'ball': 617,\n"," 'mitgebracht': 618,\n"," 'aufhalten': 619,\n"," 'gott': 620,\n"," 'kopf': 621,\n"," 'vom': 622,\n"," 'zusammen': 623,\n"," 'schließ': 624,\n"," 'bis': 625,\n"," 'aß': 626,\n"," 'wartet': 627,\n"," 'hielt': 628,\n"," 'sagt': 629,\n"," 'starb': 630,\n"," 'vögel': 631,\n"," 'hörte': 632,\n"," 'anrufen': 633,\n"," 'sauer': 634,\n"," 'blind': 635,\n"," 'voll': 636,\n"," 'meins': 637,\n"," 'lies': 638,\n"," 'komisch': 639,\n"," 'erinnere': 640,\n"," 'beeilen': 641,\n"," 'allen': 642,\n"," 'sauber': 643,\n"," 'rechnung': 644,\n"," 'pech': 645,\n"," 'brot': 646,\n"," 'verliebt': 647,\n"," 'eifersüchtig': 648,\n"," 'spiel': 649,\n"," 'gehören': 650,\n"," 'waffe': 651,\n"," 'egal': 652,\n"," 'geschlafen': 653,\n"," 'geschrieben': 654,\n"," 'füße': 655,\n"," 'sollten': 656,\n"," 'erkältung': 657,\n"," 'brauchte': 658,\n"," 'wichtig': 659,\n"," 'jahre': 660,\n"," 'frage': 661,\n"," 'nehmt': 662,\n"," 'näher': 663,\n"," 'tief': 664,\n"," 'hässlich': 665,\n"," 'schreibt': 666,\n"," 'gebe': 667,\n"," 'bringen': 668,\n"," 'stoppen': 669,\n"," 'stadt': 670,\n"," 'krieg': 671,\n"," 'schaffen': 672,\n"," 'neugierig': 673,\n"," 'drin': 674,\n"," 'kämpfen': 675,\n"," 'kennst': 676,\n"," 'bestes': 677,\n"," 'freund': 678,\n"," 'beleidigt': 679,\n"," 'denn': 680,\n"," 'müsst': 681,\n"," 'angelogen': 682,\n"," 'abendessen': 683,\n"," 'ehrlich': 684,\n"," 'wahrheit': 685,\n"," 'reise': 686,\n"," 'klingt': 687,\n"," 'namen': 688,\n"," 'niemals': 689,\n"," 'danke': 690,\n"," 'ungerecht': 691,\n"," 'bewegen': 692,\n"," 'leg': 693,\n"," 'öffnen': 694,\n"," 'hände': 695,\n"," 'mutig': 696,\n"," 'verirrt': 697,\n"," 'dünn': 698,\n"," 'haltet': 699,\n"," 'vertraue': 700,\n"," 'fliegen': 701,\n"," 'vergiss': 702,\n"," 'nacht': 703,\n"," 'pleite': 704,\n"," 'hinter': 705,\n"," 'tat': 706,\n"," 'schlief': 707,\n"," 'aufgestanden': 708,\n"," 'besorgt': 709,\n"," 'bekam': 710,\n"," 'anderer': 711,\n"," 'getrunken': 712,\n"," 'fleisch': 713,\n"," 'koch': 714,\n"," 'held': 715,\n"," 'koche': 716,\n"," 'heraus': 717,\n"," 'esst': 718,\n"," 'lang': 719,\n"," 'musste': 720,\n"," 'kuchen': 721,\n"," 'mochte': 722,\n"," 'gerettet': 723,\n"," 'eier': 724,\n"," 'naiv': 725,\n"," 'spricht': 726,\n"," 'gesungen': 727,\n"," 'hand': 728,\n"," 'hey': 729,\n"," 'anwalt': 730,\n"," 'ändern': 731,\n"," 'saß': 732,\n"," 'vermisst': 733,\n"," 'redet': 734,\n"," 'welche': 735,\n"," 'bruder': 736,\n"," 'lächeln': 737,\n"," 'sang': 738,\n"," 'aber': 739,\n"," 'schade': 740,\n"," 'gesicht': 741,\n"," 'fass': 742,\n"," 'rufe': 743,\n"," 'finde': 744,\n"," 'bescheid': 745,\n"," 'schaut': 746,\n"," 'schreiben': 747,\n"," 'antworten': 748,\n"," 'toll': 749,\n"," 'schießen': 750,\n"," 'gemeint': 751,\n"," 'pingelig': 752,\n"," 'bord': 753,\n"," 'geduldig': 754,\n"," 'berühmt': 755,\n"," 'nochmal': 756,\n"," 'mama': 757,\n"," 'fehler': 758,\n"," 'gearbeitet': 759,\n"," 'alter': 760,\n"," 'grund': 761,\n"," 'beide': 762,\n"," 'dagegen': 763,\n"," 'diät': 764,\n"," 'gesund': 765,\n"," 'verheiratet': 766,\n"," 'gefangen': 767,\n"," 'unglücklich': 768,\n"," 'spazieren': 769,\n"," 'betrogen': 770,\n"," 'erzählt': 771,\n"," 'erinnern': 772,\n"," 'verlor': 773,\n"," 'fernsehen': 774,\n"," 'genie': 775,\n"," 'zeigen': 776,\n"," 'darum': 777,\n"," 'pause': 778,\n"," 'wussten': 779,\n"," 'menschen': 780,\n"," 'besuchen': 781,\n"," 'herunter': 782,\n"," 'wenig': 783,\n"," 'chef': 784,\n"," 'liest': 785,\n"," 'riecht': 786,\n"," 'boot': 787,\n"," 'anders': 788,\n"," 'angekommen': 789,\n"," 'verraten': 790,\n"," 'mund': 791,\n"," 'zug': 792,\n"," 'fenster': 793,\n"," 'versuche': 794,\n"," 'fragt': 795,\n"," 'verstanden': 796,\n"," 'fiel': 797,\n"," 'fett': 798,\n"," 'nieder': 799,\n"," 'zahlen': 800,\n"," 'lauter': 801,\n"," 'gewusst': 802,\n"," 'richtig': 803,\n"," 'lachte': 804,\n"," 'gelangweilt': 805,\n"," 'froh': 806,\n"," 'begann': 807,\n"," 'kocht': 808,\n"," 'gesprochen': 809,\n"," 'schwimmt': 810,\n"," 'herum': 811,\n"," 'schreien': 812,\n"," 'schreit': 813,\n"," 'pflicht': 814,\n"," 'suchen': 815,\n"," 'gelacht': 816,\n"," 'grausam': 817,\n"," 'panik': 818,\n"," 'setzte': 819,\n"," 'ohne': 820,\n"," 'seite': 821,\n"," 'gas': 822,\n"," 'raucht': 823,\n"," 'mühe': 824,\n"," 'wart': 825,\n"," 'durch': 826,\n"," 'kreativ': 827,\n"," 'lügner': 828,\n"," 'fand': 829,\n"," 'lebe': 830,\n"," 'las': 831,\n"," 'treffen': 832,\n"," 'genau': 833,\n"," 'pizza': 834,\n"," 'lieber': 835,\n"," 'unschuldig': 836,\n"," 'langweile': 837,\n"," 'reicht': 838,\n"," 'leer': 839,\n"," 'singt': 840,\n"," 'schrieb': 841,\n"," 'höflich': 842,\n"," 'typ': 843,\n"," 'geschossen': 844,\n"," 'viele': 845,\n"," 'traum': 846,\n"," 'aufgeregt': 847,\n"," 'hinein': 848,\n"," 'zog': 849,\n"," 'tasse': 850,\n"," 'gewinnt': 851,\n"," 'solltest': 852,\n"," 'würdest': 853,\n"," 'messer': 854,\n"," 'enttäuscht': 855,\n"," 'spielt': 856,\n"," 'wohnt': 857,\n"," 'beeil': 858,\n"," 'fair': 859,\n"," 'leine': 860,\n"," 'scher': 861,\n"," 'rennt': 862,\n"," 'gefahren': 863,\n"," 'wasch': 864,\n"," 'ruft': 865,\n"," 'hoch': 866,\n"," 'küssen': 867,\n"," 'schauen': 868,\n"," 'weine': 869,\n"," 'lüge': 870,\n"," 'ski': 871,\n"," 'gewinne': 872,\n"," 'schrie': 873,\n"," 'schlimm': 874,\n"," 'unterschreiben': 875,\n"," 'beginnen': 876,\n"," 'pass': 877,\n"," 'gewählt': 878,\n"," 'idiot': 879,\n"," 'gefeuert': 880,\n"," 'pünktlich': 881,\n"," 'boden': 882,\n"," 'männer': 883,\n"," 'schlau': 884,\n"," 'kannte': 885,\n"," 'ausgegangen': 886,\n"," 'sache': 887,\n"," 'übel': 888,\n"," 'schaute': 889,\n"," 'schalte': 890,\n"," 'dann': 891,\n"," 'lachen': 892,\n"," 'nackt': 893,\n"," 'feigling': 894,\n"," 'beliebt': 895,\n"," 'nutzlos': 896,\n"," 'brav': 897,\n"," 'blöd': 898,\n"," 'sommer': 899,\n"," 'unter': 900,\n"," 'laut': 901,\n"," 'geantwortet': 902,\n"," 'gebt': 903,\n"," 'singe': 904,\n"," 'selten': 905,\n"," 'kanadier': 906,\n"," 'beste': 907,\n"," 'völlig': 908,\n"," 'ohren': 909,\n"," 'sollen': 910,\n"," 'billig': 911,\n"," 'schwierig': 912,\n"," 'drei': 913,\n"," 'soll': 914,\n"," 'gehst': 915,\n"," 'reinkommen': 916,\n"," 'passt': 917,\n"," 'erkältet': 918,\n"," 'dummkopf': 919,\n"," 'verkauft': 920,\n"," 'nase': 921,\n"," 'jemanden': 922,\n"," 'student': 923,\n"," 'beeindruckt': 924,\n"," 'beim': 925,\n"," 'geheimnis': 926,\n"," 'baby': 927,\n"," 'ausgeraubt': 928,\n"," 'regeln': 929,\n"," 'offen': 930,\n"," 'könnten': 931,\n"," 'feind': 932,\n"," 'leute': 933,\n"," 'trug': 934,\n"," 'name': 935,\n"," 'heimweh': 936,\n"," 'deiner': 937,\n"," 'wenn': 938,\n"," 'lauf': 939,\n"," 'entschuldigung': 940,\n"," 'schwimme': 941,\n"," 'verschwinde': 942,\n"," 'heim': 943,\n"," 'half': 944,\n"," 'töten': 945,\n"," 'aufgehört': 946,\n"," 'weint': 947,\n"," 'folge': 948,\n"," 'schönen': 949,\n"," 'ohnmächtig': 950,\n"," 'beeilt': 951,\n"," 'genommen': 952,\n"," 'wählerisch': 953,\n"," 'gar': 954,\n"," 'gelassen': 955,\n"," 'jeden': 956,\n"," 'na': 957,\n"," 'wehgetan': 958,\n"," 'angefangen': 959,\n"," 'kniete': 960,\n"," 'luft': 961,\n"," 'versprochen': 962,\n"," 'funktionieren': 963,\n"," 'rede': 964,\n"," 'fährt': 965,\n"," 'entscheiden': 966,\n"," 'verlaufen': 967,\n"," 'jungen': 968,\n"," 'verlass': 969,\n"," 'wirf': 970,\n"," 'vergeben': 971,\n"," 'lippen': 972,\n"," 'geschehen': 973,\n"," 'heißt': 974,\n"," 'stell': 975,\n"," 'verändert': 976,\n"," 'aufmerksam': 977,\n"," 'gerufen': 978,\n"," 'zieht': 979,\n"," 'gefehlt': 980,\n"," 'schläfrig': 981,\n"," 'erklären': 982,\n"," 'ärztin': 983,\n"," 'verhungern': 984,\n"," 'lernt': 985,\n"," 'träumen': 986,\n"," 'träume': 987,\n"," 'mantel': 988,\n"," 'niedergeschlagen': 989,\n"," 'ihrer': 990,\n"," 'erschossen': 991,\n"," 'unglaublich': 992,\n"," 'machst': 993,\n"," 'fische': 994,\n"," 'bekomme': 995,\n"," 'ahnung': 996,\n"," 'pferde': 997,\n"," 'freiwillig': 998,\n"," 'künstler': 999,\n"," 'gefahr': 1000,\n"," ...}"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"lzlBqTlO9bA-"},"source":["def max_length(input_tensor, target_tensor):\n","\n","    # max length of input sentense and target sentense\n","    english_len = [len(i) for i in input_tensor]\n","\n","    japanese_len = [len(i) for i in target_tensor]\n","\n","     # print max length\n","    print(\"english length:\", max(english_len))\n","    print(\"japanese length:\", max(japanese_len))\n","    max_len_input =  max(english_len)\n","    max_len_target =  max(japanese_len)\n","\n","    return max_len_input, max_len_target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ew-q24gJ9bBB","outputId":"0cafedb0-9e54-4de7-9e7e-3bdfcae03e2d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667603618861,"user_tz":-330,"elapsed":18,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}}},"source":["# Calculate max_length of the target tensors\n","max_length_input, max_length_target = max_length(input_tensor, target_tensor)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["english length: 8\n","japanese length: 12\n"]}]},{"cell_type":"code","metadata":{"id":"Y_HvHj059bBG","outputId":"e6bbd65c-4f13-4166-af16-40d217ccec11","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667603619561,"user_tz":-330,"elapsed":4,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}}},"source":["# create trainnig set and validation set\n","X_train, X_test, \\\n","    Y_train, Y_test = train_test_split(input_tensor, target_tensor, test_size=0.2, shuffle=True)\n","\n","X_test, X_val, \\\n","    Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5, shuffle=True)\n","\n","\n","# show length\n","print(len(X_train), len(Y_train), len(X_test), len(Y_test), len(X_val), len(Y_val))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["20000 20000 2500 2500 2500 2500\n"]}]},{"cell_type":"code","metadata":{"id":"w12Za_JK9bBJ"},"source":["def convert(lang, tensor):\n","    for t in tensor:\n","        if t != 0:\n","            # Index number assigned to each word\n","            print(\"%d----->%s\" % (t, lang.index_word[t]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6yT2odT9bBP","outputId":"b91c7b5f-635b-4b82-cb24-d56fa0539075","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667603620574,"user_tz":-330,"elapsed":6,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}}},"source":["print(\"input lang: index to word mapping\")\n","convert(input_lang_tokenize, X_train[10])\n","print(\"output lang: index to word mapping\")\n","convert(target_lang_tokenize, Y_train[10])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input lang: index to word mapping\n","1----->start_\n","4----->i\n","379----->wanted\n","2706----->sympathy\n","2----->_end\n","output lang: index to word mapping\n","1----->start_\n","3----->ich\n","395----->wollte\n","6451----->sympathie\n","2----->_end\n"]}]},{"cell_type":"markdown","metadata":{"id":"dSHdoFwQ9bBT"},"source":["# define parameter"]},{"cell_type":"code","metadata":{"id":"Jhj29n1l9bBT","outputId":"56819acd-0474-40d4-8662-72755a3b7c3c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667603621485,"user_tz":-330,"elapsed":4,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}}},"source":["# BUFFER_SIZE >= dataset if smaller than dataset can't shuffle equally\n","BUFFER_SIZE = len(X_train)\n","BATCH_SIZE = 32\n","dropout_rate = 0.3\n","# if None steps_per_epoch == mum of dataset\n","train_steps_per_epoch = len(X_train) // BATCH_SIZE\n","val_steps_per_epoch = len(X_val) // BATCH_SIZE\n","print(\"train step %d\" % train_steps_per_epoch)\n","embedding_dim = 300\n","units = 512\n","vocab_inp_size = len(input_lang_tokenize.word_index) + 1\n","print('Total unique words in the input: %s' % len(input_lang_tokenize.word_index))\n","print('Total unique words in the target: %s' % len(target_lang_tokenize.word_index))\n","vocab_tar_size = len(target_lang_tokenize.word_index) + 1\n","\n","# create train dataset\n","train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","\n","# create validation dataset\n","val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train step 625\n","Total unique words in the input: 4117\n","Total unique words in the target: 6514\n"]}]},{"cell_type":"markdown","metadata":{"id":"PjAVocfI9bCI"},"source":["# Encoder Model"]},{"cell_type":"code","metadata":{"id":"CJWSAHhl9bCJ"},"source":["class Encoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size, dropout_rate):\n","        super(Encoder, self).__init__()\n","        self.batch_size = batch_size\n","        self.enc_units = enc_units\n","        self.dropout = Dropout(dropout_rate)\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.first_lstm = tf.keras.layers.LSTM(self.enc_units,\n","                                                            return_sequences=True,\n","                                                            recurrent_initializer='glorot_uniform')\n","        \n","        self.final_lstm = tf.keras.layers.LSTM(self.enc_units,\n","                                                    return_sequences=True,\n","                                                    return_state=True,\n","                                                    recurrent_initializer='glorot_uniform')\n","        \n","    def call(self, x, hidden):\n","        x = self.embedding(x)\n","        x = self.dropout(x)\n","        x = self.first_lstm(x, initial_state =hidden)\n","        output, state_h, state_c = self.final_lstm(x)\n","        state = [state_h, state_c ]\n","\n","        return output, state\n","        \n","    def initialize_hidden_state(self):\n","            return tf.zeros((self.batch_size , self.enc_units)), tf.zeros((self.batch_size , self.enc_units))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V53dyDZO_F35"},"source":["encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE, dropout_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZSn1VowJ9bCS"},"source":["# attention"]},{"cell_type":"code","metadata":{"id":"cctmI1mA9bCS"},"source":["class Attention(tf.keras.models.Model):\n","\n","    def __init__(self, units: int, *args, **kwargs):\n","\n","        super().__init__(*args, **kwargs)\n","        self.units = units\n","\n","        self.q_dense_layer = Dense(units, use_bias=False, name='q_dense_layer')\n","        self.k_dense_layer = Dense(units, use_bias=False, name='k_dense_layer')\n","        self.v_dense_layer = Dense(units, use_bias=False, name='v_dense_layer')\n","        self.output_dense_layer = Dense(units, use_bias=False, name='output_dense_layer')\n","\n","    def call(self, input, memory):\n","\n","        q = self.q_dense_layer(input) \n","        k = self.k_dense_layer(memory) \n","        v = self.v_dense_layer(memory)\n","\n","        depth = self.units // 2\n","        q *= depth ** -0.5  # for scaled dot product\n","\n","        # caluclate relation between query and key\n","        logit = tf.matmul(q, k, transpose_b=True) \n","\n","        attention_weight = tf.nn.softmax(logit)\n","\n","        attention_output = tf.matmul(attention_weight, v) \n","        return self.output_dense_layer(attention_output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBBPzDxK9bCg"},"source":["# Decoder Model"]},{"cell_type":"code","metadata":{"id":"1nED5gCZ9bCh"},"source":["class Decoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size, dropout_rate):\n","        super(Decoder, self).__init__()\n","        self.batch_size = batch_size\n","        self.dec_units = dec_units\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.dropout = Dropout(dropout_rate)\n","        self.first_lstm = tf.keras.layers.LSTM(self.dec_units,\n","                                                            return_sequences=True)\n","        self.final_lstm = tf.keras.layers.LSTM(self.dec_units,\n","                                                            return_sequences=True,\n","                                                            return_state=True)\n","                                                            \n","        self.fc = tf.keras.layers.Dense(vocab_size)\n","        \n","        self.attention = Attention(self.dec_units)\n","    \n","    def call(self, x, hidden, enc_output):\n","        x = self.embedding(x)\n","        x = self.dropout(x)\n","        \n","        x =  self.first_lstm(x)\n","        output, state_h, state_c = self.final_lstm(x)\n","        state = [state_h, state_c]\n","        attention_weights = self.attention(output, enc_output)\n","        output = tf.concat([output, attention_weights], axis=-1)\n","\n","                \n","        output = tf.reshape(output, (-1, output.shape[2]))\n","        \n","        output = self.fc(output)\n","        \n","        return  output, state"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"37-lrVTN_F4X"},"source":["decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, dropout_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fvyXf1bn9bC1"},"source":["# optimizer and the loss function"]},{"cell_type":"code","metadata":{"id":"wROZueWU9bC3"},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.9, epsilon=1e-04, decay=1e-06)\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DtDLuqB49bC7"},"source":["# Checkpoints"]},{"cell_type":"code","metadata":{"id":"0CWEvq3W9bC8"},"source":["checkpoint_dir = './train_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ja0mhQ4j9bDB"},"source":["# train model"]},{"cell_type":"code","metadata":{"id":"TQSV9kkd9bDB"},"source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([target_lang_tokenize.word_index['start_']] * BATCH_SIZE, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","      # passing enc_output to the sladecoder\n","      predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n","\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # using teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCI9q4-C9bDI","outputId":"6f636a3b-eb04-4628-ade3-63a71df2704d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667603809585,"user_tz":-330,"elapsed":181018,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}}},"source":["# trained model for 45 epochs\n","EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","  \n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  train_loss = 0\n","  val_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(train_dataset.take(train_steps_per_epoch)):\n","    train_batch_loss = train_step(inp, targ, enc_hidden)\n","    train_loss += train_batch_loss\n","\n","\n","  for (batch, (val_inp, val_tar)) in enumerate(val_dataset.take(val_steps_per_epoch)):\n","    val_batch_loss = train_step(val_inp, val_tar, enc_hidden)\n","    val_loss += val_batch_loss\n","\n","\n","  # saving (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  print('Epoch {} Train Loss {:.4f}'.format(epoch + 1,\n","                                      train_loss / train_steps_per_epoch))\n","  print('Epoch {} Validation Loss {:.4f}'.format(epoch + 1,\n","                                      val_loss / val_steps_per_epoch))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Train Loss 1.8013\n","Epoch 1 Validation Loss 1.5329\n","Epoch 2 Train Loss 1.4135\n","Epoch 2 Validation Loss 1.3033\n","Epoch 3 Train Loss 1.2274\n","Epoch 3 Validation Loss 1.1478\n","Epoch 4 Train Loss 1.0872\n","Epoch 4 Validation Loss 1.0166\n","Epoch 5 Train Loss 0.9833\n","Epoch 5 Validation Loss 0.9263\n"]}]},{"cell_type":"markdown","metadata":{"id":"0gu5bPpdEHVz"},"source":["## **Evaluation:**\n","\n","(Check bleu score)"]},{"cell_type":"code","metadata":{"id":"wJ8r9JNREs01"},"source":["def predict(sentence):\n","    inputs = tf.convert_to_tensor(sentence)\n","    result = ''\n","    inputs = tf.expand_dims(inputs, axis=0)\n","    hidden = [tf.zeros((1, units)), tf.zeros((1, units))]\n","    enc_out, state = encoder(inputs, hidden)\n","    hidden_state = state\n","    dec_input = tf.expand_dims([target_lang_tokenize.word_index['start_']], 0)\n","    for t in range(max_length_target):\n","        predictions, hidden_state = decoder(dec_input,\n","                                                             hidden_state,\n","                                                             enc_out)\n","\n","        predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","        result += target_lang_tokenize.index_word[predicted_id] + ' '\n","        if target_lang_tokenize.index_word[predicted_id] == '_end' or len(result) > max_length_target:\n","            return result\n","\n","        # the predicted ID is fed back into the model\n","        dec_input = tf.expand_dims([predicted_id], 0)\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"87pBzvXjRkJL"},"source":["def create_reference(lang, tensor):\n","    all_sentence_list = []\n","\n","    for word_list in tensor:\n","      sentence_list = []\n","\n","      for t in word_list:\n","          if not t == 0:\n","              # Index number assigned to each word\n","              sentence_list.append(lang.index_word[t])\n","      all_sentence_list.append(sentence_list)\n","    return all_sentence_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGwwlmHtRrfb"},"source":["# create reference\n","reference = create_reference(target_lang_tokenize, Y_test.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAAMX-vQEKB_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8e8f6d3-6064-47a1-8751-1542058602d2","executionInfo":{"status":"ok","timestamp":1667603975316,"user_tz":-330,"elapsed":133896,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}}},"source":["from tqdm import tqdm\n","# create hypothesis\n","hypothesis = []\n","for i in tqdm(X_test):\n","  hypothesis.append(predict(i))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2500/2500 [02:14<00:00, 18.63it/s]\n"]}]},{"cell_type":"markdown","source":["### Evaluating the performance of the model using BLEU Score:"],"metadata":{"id":"00THOtLe_Ko0"}},{"cell_type":"code","metadata":{"id":"-i0Jl_21Ee7k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1732d38-6a52-403f-d991-27fa4cd908be","executionInfo":{"status":"ok","timestamp":1667603976000,"user_tz":-330,"elapsed":699,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}}},"source":["from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","score = 0\n","smoothie = SmoothingFunction().method2\n","for i in range(len(reference)):\n","    score += sentence_bleu([reference[i][1:-1]], hypothesis[i][:-5].strip().split(), smoothing_function=smoothie)\n","\n","score /= len(reference)\n","print(\"The bleu score is: \"+str(score))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The bleu score is: 0.29664571692216046\n"]}]},{"cell_type":"markdown","metadata":{"id":"TNkXiemq9bDO"},"source":["# Translation example"]},{"cell_type":"code","metadata":{"id":"J-DcisWA9bDP"},"source":["def preprocess_sentence(en_text):\n","        # normalize English\n","        en_text = en_text.lower()\n","\n","        en_text = \"start_ \" + en_text + \" _end\"\n","\n","        return en_text\n","        \n","def evaluate(sentence):\n","  \n","    attention_plot = np.zeros((max_length_target, max_length_input))\n","\n","    sentence = preprocess_sentence(sentence)\n","    inputs = [input_lang_tokenize.word_index[i] for i in sentence.split(' ')]\n","\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                           maxlen=max_length_input,\n","                                                           padding='post')\n","    \n","    inputs = tf.convert_to_tensor(inputs)\n","    result = ''\n","    hidden = [tf.zeros((1, units)), tf.zeros((1, units))]\n","    enc_out, state = encoder(inputs, hidden)\n","    hidden_state = state\n","    dec_input = tf.expand_dims([target_lang_tokenize.word_index['start_']], 0)\n","    for t in range(max_length_target):\n","        predictions, hidden_state = decoder(dec_input,\n","                                                             hidden_state,\n","                                                             enc_out)\n","        predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","        result += target_lang_tokenize.index_word[predicted_id] + ' '\n","        if target_lang_tokenize.index_word[predicted_id] == '_end' or len(result) > max_length_target:\n","            return result, sentence\n","\n","        # the predicted ID is fed back into the model\n","        dec_input = tf.expand_dims([predicted_id], 0)\n","    return result, sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ui6bFxRt9bDd"},"source":["from nltk.translate.bleu_score import sentence_bleu\n","\n","def result(sentence):\n","    result, sentence = evaluate(sentence)\n","\n","    return result, sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2duMXKX9bDh","outputId":"b7a00997-ddf6-4436-ea42-9b546e549903","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667604226136,"user_tz":-330,"elapsed":3,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}}},"source":["result, sentence = evaluate(\"he has a dog\")\n","print('Input: %s' % (sentence))\n","print('Predicted translation: {}'.format(result))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: start_ he has a dog _end\n","Predicted translation: er hat einen \n"]}]},{"cell_type":"code","metadata":{"id":"67d09FoPz2Al","outputId":"ae3731c6-73d7-46b4-9be5-a67272b2724b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667604161781,"user_tz":-330,"elapsed":413,"user":{"displayName":"Venkata Ratna","userId":"10796771328777583033"}}},"source":["result, sentence = evaluate(\"I love her\")\n","print('Input: %s' % (sentence))\n","print('Predicted translation: {}'.format(result))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: start_ i love her _end\n","Predicted translation: ich liebe sie \n"]}]},{"cell_type":"code","metadata":{"id":"J2saSpKK0Cwl"},"source":["while(1):\n","  sent = input(\"Enter the sentence: \")\n","  if(sent == \"quit\"):\n","    break\n","  else:\n","    result, sentence = evaluate(sent)\n","    print('Input: %s' % (sentence))\n","    print('Predicted translation: {}\\n'.format(result))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Mi001PWh93LB"},"execution_count":null,"outputs":[]}]}